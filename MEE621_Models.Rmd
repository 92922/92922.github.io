---
title: "MEE 621 - Activity 9 Models"
output:
  html_document:
    df_print: paged
  pdf_document: default
  html_notebook: default
---

 <h3> This is the answers of the exercise by Junmar Sales II </h3>
 <h3> Email: 92922@usc.edu.ph </h3>
 <h3> Dated 06 December 2020. </h3>
 <h3>  You can also see this on my github pages: <a href="https://92922.github.io/dist/MEE621_PipesFunctionsIterationsVectors.html" >MEE 621 - Activity 9 Models</a>  </h3>


<h1 style="color:blue"> INTRODUCTIONS </h1>

<p>
So far we have touched different packages in R and its main usage. These packages are the following:

<div> - <u><b>ggplot2</b></u>: for Data visualisation</div>
<div> - <u><b>dplyr</b></u>: for Data manipulation</div>
<div> - <u><b>tibbles</b></u>: for Data frames</div>
<div> - <u><b>readr</b></u>: for Data import</div>
<div> - <u><b>tidyr</b></u>: for data tidying</div>
<div> - <u><b>lubridate</b></u>: for Date/times</div>
<div> - <u><b>magrittr</b></u>: for Pipes</div>
<div> - <u><b>purr</b></u>: for Functional programming</div>

<div>
Now, we will explore another package for modeling. The
<u><b>modelr</b></u> used for Modeling.

The goal of this package is to provide functions that help you create elegant pipelines when modeling.  It is designed primarily to support teaching the basics of modeling within the ```tidyverse```. In this package, we have functions for modelling that help you seamlessly integrate modeling into a pipeline of data manipulation and visualization.

</div>



<div>
But before diving into the package on how to use it, we will somehow tackle modeling  basic concepts, building a model and some complex models with ```purrr``` and ```broom```.
</div>

</p>


<h1 style="color:blue"> ANSWERS TO EXERCISES AND DISCUSSIONS  </h1>

Let's load the prerequisite libraries, we have assumed that packages has been installed.

```{r}
library(tidyverse)
library(modelr)
options(na.action = na.warn)
library("lubridate")
library("broom")
library("nycflights13")
library("splines")
library("dplyr")
library("gridExtra")
library("gapminder")
library("ggbeeswarm")
```


<h2 style="color:magenta">23.2.1 Exercises</h2>

<h3 style="color:green">
1. One downside of the linear model is that it is sensitive to unusual values because the
distance incorporates a squared term. Fit a linear model to the simulated data below, and
visualize the results. Rerun a few times to generate different simulated datasets. What do
you notice about the model?
```{r}
sim1_mod <- lm(y ~ x, data = sim1)
```

```{r}
sim1a <- tibble(
x = rep(1:10, each = 3),
y = x * 1.5 + 6 + rt(length(x), df = 2)
)
```
</h3>

Let's generate n number of datasets that fit characteristics of sim1a

```{r}
sim1a_mult <- tibble(num = 1:500) %>%
  rowwise() %>%
  mutate(data = list(tibble(
    x = rep(1:10, each = 3),
    y = x * 1.5 + 6 + rt(length(x), df = 2)
  ))) %>%
  #undoes rowwise (used to have much more of workflow with rowwise, but have
  #changed to use more of map)
  ungroup()

plots_prep <- sim1a_mult %>% 
  mutate(mods = map(data, ~lm(y ~ x, data = .x))) %>% 
  mutate(preds = map2(data, mods, modelr::add_predictions),
         rmse = map2_dbl(mods, data, modelr::rmse),
         mae = map2_dbl(mods, data, modelr::mae))

```

```{r}
plots_prep %>% 
  ggplot(aes(x = "rmse", y = rmse))+
  ggbeeswarm::geom_beeswarm()
```
As a metric, it tends to be more susceptible to outliers, than say mae.

Let’s try another approach and run it once and then, plot the results:

```{r}

simt <- function(i) {
  tibble(
    x = rep(1:10, each = 3),
    y = x * 1.5 + 6 + rt(length(x), df = 2),
    .id = i
  )
}

sims <- map_df(1:12, simt)

ggplot(sims, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", colour = "green") +
  facet_wrap(~.id, ncol = 4)
```
We can observe it systematically, by generating several simulations and plotting the line like above.

What if we did the same things with normal distributions?

```{r}
sim_norm <- function(i) {
  tibble(
    x = rep(1:10, each = 3),
    y = x * 1.5 + 6 + rnorm(length(x)),
    .id = i
  )
}

simdf_norm <- map_df(1:12, sim_norm)

ggplot(simdf_norm, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", colour = "magenta") +
  facet_wrap(~.id, ncol = 4)
```
There are no large outliers, and the slopes are more similar.

The reason for this is that the Student’s  t-distribution, from which we sample with rt() has heavier tails than the normal distribution (rnorm()). This means that the Student’s t-distribution assigns a larger probability to values further from the center of the distribution.
 
```{r}
tibble(
  x = seq(-5, 5, length.out = 100),
  normal = dnorm(x),
  student_t = dt(x, df = 2)
) %>%
  pivot_longer(-x, names_to="distribution", values_to="density") %>%
  ggplot(aes(x = x, y = density, colour = distribution)) +
  geom_line()
```
For a normal distribution with mean zero and standard deviation one, the probability of being greater than 2 is,

```{r}
pnorm(2, lower.tail = FALSE)
```
For a Student’st  distribution with degrees of freedom = 2, it is more than 3 times higher,


```{r}
pt(2, df = 2, lower.tail = FALSE)
```


<h3 style="color:green">
2. One way to make linear models more robust is to use a different distance measure. For
example, instead of root-mean-squared distance, you could use mean-absolute distance:

```{r}
measure_distance <- function(mod, data) {
diff <- data$y - model1(mod, data)
mean(abs(diff))
}
```

Use ```optim()``` to fit this model to the simulated data above and compare it to the linear
model.
</h3>

```{r}
model_1df <- function(betas, x1 = sim1$x) {
  betas[1] + x1 * betas[2]
}

measure_mae <- function(mod, data) {
  diff <- data$y - model_1df(betas = mod, data$x)
  mean(abs(diff))
}

measure_rmse <- function(mod, data) {
  diff <- data$y - model_1df(betas = mod, data$x)
  sqrt(mean(diff^2))
}

best_mae_sims <- map(sim1a_mult$data, ~optim(c(0,0), measure_mae, data = .x))
best_rmse_sims <- map(sim1a_mult$data, ~optim(c(0,0), measure_rmse, data = .x))
mae_df <- best_mae_sims %>% 
  map("value") %>% 
  transpose() %>% 
  set_names(c("error")) %>% 
  as_tibble() %>% 
  unnest() %>% 
  mutate(error_type = "mae", 
         row_n = row_number())

rmse_df <- best_rmse_sims %>% 
  map("value") %>% 
  transpose() %>% 
  set_names(c("error")) %>% 
  as_tibble() %>% 
  unnest() %>% 
  mutate(error_type = "rmse",
         row_n = row_number())
bind_rows(rmse_df, mae_df) %>% 
  ggplot(aes(x = error_type, colour = error_type))+
  ggbeeswarm::geom_beeswarm(aes(y = error))+
  facet_wrap(~error_type, scales = "free_x")
```
Now, we can see the error for rmse seems to have more extreme based on the examples.


<h3 style="color:green">

3. One challenge with performing numerical optimisation is that it’s only guaranteed to find
one local optimum. What’s the problem with optimising a three parameter model like
this?

```{r}
model1 <- function(a, data) {
a[1] + data$x * a[2] + a[3]
}
```
</h3>



The problem is that is that there are multiple “best” solutions in this example. a[1] and a[3] together represent the intercept here.

```{r}
models_two <- vector("list", 2)

model1 <- function(a, data) {
  a[1] + data$x * a[2] + a[3]
}

models_two[[1]] <- optim(c(0, 0, 0), measure_rmse, data = sim1)
models_two[[1]]$par
## [1]  4.219814  2.051678 -3.049197
model1 <- function(a, data) {
  a[1] + data$x * a[2]
}

models_two[[2]] <- optim(c(0, 0), measure_rmse, data = sim1)

models_two
```
It seems that a1 and a3 are essentially equivalent, so optimizes somewhat arbitrarily, in this case can see the a1+a3 in the 1st (when there are 3 parameters) is equal to a1 in the 2nd (when there are only two parameters)…40




<h2 style="color:magenta">23.3.3 Exercises</h2>

<h3 style="color:green">
1. Instead of using ```lm()``` to fit a straight line, you can use ```loess()``` to fit a smooth curve.
Repeat the process of model fitting, grid generation, predictions, and visualisation on
sim1 using ```loess()``` instead of ```lm()``` . How does the result compare to
geom_smooth() ?
</h3>


I’ll use add_predictions() and add_residuals() to add the predictions and residuals from a loess regression to the sim1 data.

```{r}
sim1_loess <- loess(y ~ x, data = sim1)
sim1_lm <- lm(y ~ x, data = sim1)

grid_loess <- sim1 %>%
  add_predictions(sim1_loess)

sim1 <- sim1 %>%
  add_residuals(sim1_lm) %>%
  add_predictions(sim1_lm) %>%
  add_residuals(sim1_loess, var = "resid_loess") %>%
  add_predictions(sim1_loess, var = "pred_loess")
```

This plots the loess predictions. The loess produces a nonlinear, smooth line through the data.

```{r}
plot_sim1_loess <-
  ggplot(sim1, aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(x = x, y = pred), data = grid_loess, colour = "magenta")
plot_sim1_loess
```

The predictions of loess are the same as the default method for geom_smooth() because geom_smooth() uses loess() by default; the message even tells us that.

```{r}
plot_sim1_loess +
  geom_smooth(method = "loess", colour = "purple", se = FALSE, alpha = 0.20)
#> `geom_smooth()` using formula 'y ~ x'
```

We can plot the residuals (red), and compare them to the residuals from lm() (black). In general, the loess model has smaller residuals within the sample (out of sample is a different issue, and we haven’t considered the uncertainty of these estimates).
```{r}
ggplot(sim1, aes(x = x)) +
  geom_ref_line(h = 0) +
  geom_point(aes(y = resid)) +
  geom_point(aes(y = resid_loess), colour = "red")
```  
  


<h3 style="color:green">
2. ```add_predictions()``` is paired with ```gather_predictions()``` and ```spread_predictions()``` . How do these three functions differ?
</h3>

The functions gather_predictions() and spread_predictions() allow for adding predictions from multiple models at once.

Taking the sim1_mod example,

```{r}
sim1_mod <- lm(y ~ x, data = sim1)
grid <- sim1 %>%
  data_grid(x)
```
The function add_predictions() adds only a single model at a time. To add two models:

```{r}
grid %>%
  add_predictions(sim1_mod, var = "pred_lm") %>%
  add_predictions(sim1_loess, var = "pred_loess")
```

The function gather_predictions() adds predictions from multiple models by stacking the results and adding a column with the model name,

```{r}
grid %>%
  gather_predictions(sim1_mod, sim1_loess)
```

The function spread_predictions() adds predictions from multiple models by adding multiple columns (postfixed with the model name) with predictions from each model.

```{r}
grid %>%
  spread_predictions(sim1_mod, sim1_loess)
```

The function spread_predictions() is similar to the example which runs add_predictions() for each model, and is equivalent to running spread() after running gather_predictions():

```{r}
grid %>%
  gather_predictions(sim1_mod, sim1_loess) %>%
  spread(model, pred)
```


<h3 style="color:green">
3. What does ```geom_ref_line()``` do? What package does it come from? Why is displaying a reference line in plots showing residuals useful and important?
</h3>

The geom ```geom_ref_line()``` adds as reference line to a plot. It is equivalent to running ```geom_hline()``` or ```geom_vline()``` with default settings that are useful for visualizing models. Putting a reference line at zero for residuals is important because good models (generally) should have residuals centered at zero, with approximately the same variance (or distribution) over the support of x, and no correlation. A zero reference line makes it easier to judge these characteristics visually.

It comes from ```ggplot2``` and shows either a ```geom_hline``` or a ```geom_vline```, depending on whether you specify h or v. ```ggplot2::geom_ref_line```



<h3 style="color:green">
4. Why might you want to look at a frequency polygon of absolute residuals? What are the
pros and cons compared to looking at the raw residuals?
</h3>

Maybe good for situations when you have TONS of residuals, and is hard to look at?…
pros are it may be easier to get sense of count, cons are that you can’t plot it against something like x so patterns associated with residuals will not be picked-up, e.g. heteroskedasticity, or more simply, signs that the model could be improved by incorporating other vars in the model

Showing the absolute values of the residuals makes it easier to view the spread of the residuals. The model assumes that the residuals have mean zero, and using the absolute values of the residuals effectively doubles the number of residuals.

```{r}
sim1_mod <- lm(y ~ x, data = sim1)

sim1 <- sim1 %>%
  add_residuals(sim1_mod)

ggplot(sim1, aes(x = abs(resid))) +
  geom_freqpoly(binwidth = 0.5)
```
However, using the absolute values of residuals throws away information about the sign, meaning that the frequency polygon cannot show whether the model systematically over- or under-estimates the residuals.



<h2 style="color:magenta">23.4.5 Exercises</h2>

<h3 style="color:green">
1. What happens if you repeat the analysis of sim2 using a model without an intercept. What happens to the model equation? What happens to the predictions?
</h3>


To run a model without an intercept, add - 1 or + 0 to the right-hand-side o f the formula:
```{r}
mod2a <- lm(y ~ x - 1, data = sim2)
mod2 <- lm(y ~ x, data = sim2)
```

The predictions are exactly the same in the models with and without an intercept:

```{r}
grid <- sim2 %>%
  data_grid(x) %>%
  spread_predictions(mod2, mod2a)
grid
```

<h3 style="color:green">
2. Use ```model_matrix()``` to explore the equations generated for the models I fit to ```sim3``` and ```sim4``` . Why is * a good shorthand for interaction?
</h3>


```{r}
model_matrix(y ~ x1 * x2, data = sim3)
```

```{r}
model_matrix(y ~ x1 * x2, data = sim4)
```

Now, it is because each of the levels are multiplied by one another (just don’t have to write in the design variables).


<h3 style="color:green">
3. Using the basic principles, convert the formulas in the following two models into functions. (Hint: start by converting the categorical variable into 0-1 variables.)
```{r}
mod1 <- lm(y ~ x1 + x2, data = sim3)
mod2 <- lm(y ~ x1 * x2, data = sim3)
```
</h3>


The problem is to convert the formulas in the models into functions. I will assume that the function is only handling the conversion of the right hand side of the formula into a model matrix. The functions will take one argument, a data frame with x1 and x2 columns, and it will return a data frame. In other words, the functions will be special cases of the model_matrix() function.

Consider the right hand side of the first formula, ~ x1 + x2. In the sim3 data frame, the column x1 is an integer, and the variable x2 is a factor with four levels.

```{r}
levels(sim3$x2)
```

Since x1 is numeric it is unchanged. Since x2 is a factor it is replaced with columns of indicator variables for all but one of its levels. I will first consider the special case in which x2 only takes the levels of x2 in sim3. In this case, “a” is considered the reference level and omitted, and new columns are made for “b”, “c”, and “d”.

```{r}
model_matrix_mod1 <- function(.data) {
  mutate(.data,
    x2b = as.numeric(x2 == "b"),
    x2c = as.numeric(x2 == "c"),
    x2d = as.numeric(x2 == "d"),
    `(Intercept)` = 1
  ) %>%
    select(`(Intercept)`, x1, x2b, x2c, x2d)
}

```

```{r}
model_matrix_mod1(sim3)
```
A more general function for ~ x1 + x2 would not hard-code the specific levels in x2.

```{r}
model_matrix_mod1b <- function(.data) {
  # the levels of x2
  lvls <- levels(.data$x2)
  # drop the first level
  # this assumes that there are at least two levels
  lvls <- lvls[2:length(lvls)]
  # create an indicator variable for each level of x2
  for (lvl in lvls) {
    # new column name x2 + level name
    varname <- str_c("x2", lvl)
    # add indicator variable for lvl
    .data[[varname]] <- as.numeric(.data$x2 == lvl)
  }
  # generate the list of variables to keep
  x2_variables <- str_c("x2", lvls)
  # Add an intercept
  .data[["(Intercept)"]] <- 1
  # keep x1 and x2 indicator variables
  select(.data, `(Intercept)`, x1, all_of(x2_variables))
}
```

```{r}
model_matrix_mod1b(sim3)
```
Consider the right hand side of the first formula, ~ x1 * x2. The output data frame will consist of x1, columns with indicator variables for each level (except the reference level) of x2, and columns with the x2 indicator variables multiplied by x1.

As with the previous formula, first I’ll write a function that hard-codes the levels of x2.

```{r}
model_matrix_mod2 <- function(.data) {
  mutate(.data,
    `(Intercept)` = 1,
    x2b = as.numeric(x2 == "b"),
    x2c = as.numeric(x2 == "c"),
    x2d = as.numeric(x2 == "d"),
    `x1:x2b` = x1 * x2b,
    `x1:x2c` = x1 * x2c,
    `x1:x2d` = x1 * x2d
  ) %>%
    select(`(Intercept)`, x1, x2b, x2c, x2d, `x1:x2b`, `x1:x2c`, `x1:x2d`)
}
```

```{r}
model_matrix_mod2(sim3)
```
For a more general function which will handle arbitrary levels in x2, I will extend the model_matrix_mod1b() function that I wrote earlier.

```{r}
model_matrix_mod2b <- function(.data) {
  # get dataset with x1 and x2 indicator variables
  out <- model_matrix_mod1b(.data)
  # get names of the x2 indicator columns
  x2cols <- str_subset(colnames(out), "^x2")
  # create interactions between x1 and the x2 indicator columns
  for (varname in x2cols) {
    # name of the interaction variable
    newvar <- str_c("x1:", varname)
    out[[newvar]] <- out$x1 * out[[varname]]
  }
  out
}

```

```{r}
model_matrix_mod2b(sim3)
```
These functions could be further generalized to allow for x1 and x2 to be either numeric or factors. However, generalizing much more than that and we will soon start reimplementing all of the matrix_model() function.


<h3 style="color:green">
4. For ```sim4``` , which of ```mod1``` and ```mod2``` is better? I think ```mod2``` does a slightly better job at removing patterns, but it’s pretty subtle. Can you come up with a plot to support my claim?
</h3>

```{r}
mod1 <- lm(y ~ x1 + x2, data = sim4)
mod2 <- lm(y ~ x1 * x2, data = sim4)

grid <-  modelr::seq_range(sim4$x1, n = 3, pretty = TRUE)

sim4 %>% 
  gather_residuals(mod1, mod2) %>% 
  mutate(resid_abs = (resid)^2) %>% 
  group_by(model) %>% 
  summarise(rmse = sqrt(mean(resid_abs)))
```


* The aggregate `rmse` between the two models is nearly the same.


```{r}
sim4 %>% 
  gather_residuals(mod1, mod2) %>% 
  ggplot(aes(x = resid, fill = model, group = model))+
  geom_density(alpha = 0.3)
```

* If you observed it, any difference in resids is pretty subtle...

* Let's plot them though and see how their predictions differ*

```{r}
sim4 %>% 
  spread_residuals(mod1, mod2) %>% 
  gather_predictions(mod1, mod2) %>% 
  ggplot(aes(x1, pred, colour = x2, group = x2))+
  geom_line()+
  geom_point(aes(y = y), alpha = 0.3)+
  facet_wrap(~model)
```


* Notice subtle difference where for mod2 as x2 decreases, the predicted value for x1 also decreases, this is because the interaciton term between these is positive
* the values near where x2 and x1 are most near 0 should be where the residuals are most similar

*Plot difference in residuals*

```{r}
sim4 %>% 
  spread_residuals(mod1, mod2) %>% 
  mutate(mod2_less_mod1 = mod2 - mod1) %>% 
  group_by(x1, x2) %>% 
  summarise(mod2_less_mod1 = mean(mod2_less_mod1) ) %>% 
  ungroup() %>% 
  ggplot(aes(x = x1, y = x2))+
  geom_tile(aes(fill = mod2_less_mod1))+
  geom_text(aes(label = round(mod2_less_mod1, 1)), size = 3)+
  scale_fill_gradient2()
```

* This shows how `mod2` has higher valued predictions when x1 and x2 are opposite signs compared to the predictions from `mod1`

*Plot difference in distance from 0 between `mod1` and `mod1` resids*

```{r}
sim4 %>% 
  spread_residuals(mod1, mod2) %>% 
  mutate_at(c("mod1", "mod2"), abs) %>%
  mutate(mod2_less_mod1 = mod2 - mod1) %>% 
  group_by(x1, x2) %>% 
  summarise(mod2_less_mod1 = mean(mod2_less_mod1) ) %>% 
  ungroup() %>% 
  ggplot(aes(x = x1, y = x2))+
  geom_tile(aes(fill = mod2_less_mod1))+
  geom_text(aes(label = round(mod2_less_mod1, 1)), size = 3)+
  scale_fill_gradient2()
```

* See slightly more red than blue indicating that `mod2` may, in general, have slightly smaller residuals on a wider range of locations
* However little and `mod1` has advantage of simplicity
  
  

<h2 style="color:magenta">24.2: Why are low quality diamonds more expensive?</h2>

This code appears in the section and is necessary for the exercises.
```{r}
# model for only small diamonds
diamonds2 <- diamonds %>% 
  filter(carat <= 2.5) %>% 
  mutate(lprice = log2(price), 
         lcarat = log2(carat))

mod_diamond <- lm(lprice ~ lcarat, data = diamonds2)

mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds2)

diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond2, "resid_lg")
```

<h2 style="color:magenta">24.2.3 Exercises</h2>

<h3 style="color:green">
1. In the plot of ```lcarat``` vs. ```lprice``` , there are some bright vertical strips. What do they represent?
</h3>


```{r}
plot_lc_lp <- diamonds2 %>% 
  ggplot(aes(lcarat, lprice))+
  geom_hex(show.legend = FALSE)

plot_lp_lc <- diamonds2 %>% 
  ggplot(aes(lprice, lcarat))+
  geom_hex(show.legend = FALSE)

plot_lp <- diamonds2 %>%
  ggplot(aes(lprice))+
  geom_histogram(binwidth = .1)

plot_lc <- diamonds2 %>%
  ggplot(aes(lcarat))+
  geom_histogram(binwidth = 0.1)

gridExtra::grid.arrange(plot_lc_lp, plot_lc, plot_lp + coord_flip()) 
```

The vertical bands correspond with clumps of carat_lg values falling across a range of price_lg values
Histogram of carat values:

```{r}
diamonds2 %>% 
  ggplot(aes(carat))+
  geom_histogram(binwidth = 0.01)+
  scale_x_continuous(breaks = seq(0, 2, 0.1))
```  
- The chart above shows spikes in carat values at 0.3, 0.4, 0.41, 0.5, 0.7, 0.9, 1.0, 1.01, 1.2, 1.5, 1.7 and 2.0, each distribution spikes at that value and then decreases until hitting the next spike
- This suggests there is a preference for round numbers ending on tenths
- It’s curious why you don’t see really see spikes at 0.6, 0.8, 0.9, 1.1, 1.3, 1.4, 1.6, 1.8, 1.9, it suggests either there is something special about those paricular values – perhaps diamonds just tend to develop near those sizes so are more available in sizes of 0.7 than say 0.8


<h3 style="color:green">
2. If ```log(price) = a_0 + a_1 * log(carat)``` , what does that say about the relationship between price and carat ?
</h3>


- Since we’re using a natural log it means that an a_1 percentage change in carat corresponds with an a_1 percentage increase in the price
- If you had used a log base 2 it has a different interpretation that can be thought of in terms of relationship of doubling


- Below is an example using a base-2 logarithm.

```{r}
mod_log <- lm(log2(price) ~ log2(carat), data = diamonds)
mod_log
```

- The estimated relationship between carat and price looks like this.

```{r}
tibble(carat = seq(0.25, 5, by = 0.25)) %>%
  add_predictions(mod_log) %>%
  ggplot(aes(x = carat, y = 2^pred)) +
  geom_line() +
  labs(x = "carat", y = "price")
```
- The plot shows that the estimated relationship between carat and price is not linear. The exact relationship in this model is if  x  increases r  times, then  y  increases ra1  times. 
  


<h3 style="color:green">
3. Extract the diamonds that have very high and very low residuals. Is there anything unusual about these diamonds? Are they particularly bad or good, or do you think these are pricing errors?
</h3>

```{r}
extreme_vals <- diamonds2 %>% 
  mutate(extreme_value = (abs(resid_lg) > 1)) %>% 
  filter(extreme_value) %>% 
  add_predictions(mod_diamond2, "pred_lg") %>% 
  mutate(price_pred = 2^(pred_lg))
```


```{r}
diamonds2 %>% 
  add_predictions(mod_diamond2) %>% 
  # mutate(extreme_value = (abs(resid_lg) > 1)) %>% 
  # filter(!extreme_value) %>% 
  ggplot(aes(carat, price))+
  geom_hex(bins = 50)+
  geom_point(aes(carat, price), data = extreme_vals, color = "red")
```
- It’s possible some of these these were mislabeled or errors, e.g. an error in typing e.g. 200 miswritten as 2000, though given the wide range in pricing this does not seem like that extreme of a variation.

```{r}
diamonds2 %>% 
  add_predictions(mod_diamond2) %>% 
  mutate(extreme_value = (abs(resid_lg) > 1),
         price_pred = 2^pred) %>%
  filter(extreme_value) %>% 
  mutate(multiple = price / price_pred) %>% 
  arrange(desc(multiple)) %>% 
  select(price, price_pred, multiple)
```
- If the mislabeling were an issue of e.g. 200 to 2000, you would expect that some of the actual values were ~1/10th or 10x the value of the predicted value. Though none of them appear to have this issue, except for maybe the item that was priced at 2160 but has a price of 314, which is the closest error where the actual value was ~1/10th the value of the prediction


<h3 style="color:green">
4. Does the final model, ```mod_diamond2``` , do a good job of predicting diamond prices?
Would you trust it to tell you how much to spend if you were buying a diamond?
</h3>

```{r}
perc_unexplained <- diamonds2 %>% 
  add_predictions(mod_diamond2, "pred") %>% 
  mutate(pred_2 = 2^pred,
         mean_price = mean(price),
         error_deviation = (price - pred_2)^2,
         reg_deviation = (pred_2 - mean_price)^2,
         tot_deviation = (price - mean_price)^2) %>% 
  summarise(R_squared = sum(error_deviation) / sum(tot_deviation)) %>% 
  flatten_dbl()

1 - perc_unexplained
```  
- ~96.5% of variance is explained by model which seems pretty solid, though is relative to each situation
- Whether you think that this is a good model depends on factors outside the statistical model itself. It will depend on the how the model is being used. I have no idea how to price diamonds, so this would be useful to me in order to understand a reasonable price range for a diamond, so I don’t get ripped off. However, if I were buying and selling diamonds as a business, I would probably require a better model.

  
<h2 style="color:magenta">24.3 What affects the number of daily flights?</h2>


Some useful notes copied from this particular section and might be used in succeeding exercises:

```{r}
daily <- flights %>% 
  mutate(date = make_date(year, month, day)) %>% 
  count(date)

daily <- daily %>% 
  mutate(month = month(date, label = TRUE))

daily <- daily %>% 
  mutate(wday = wday(date, label = TRUE))


term <- function(date) {
  cut(date, 
    breaks = ymd(20130101, 20130605, 20130825, 20140101),
    labels = c("spring", "summer", "fall") 
  )
}

daily <- daily %>% 
  mutate(term = term(date))

daily %>% 
  filter(wday == "Sat") %>% 
  ggplot(aes(date, n, colour = term))+
  geom_point(alpha = .3)+
  geom_line()+
  scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```  
<h2 style="color:magenta">24.3.5 Exercises</h2>


<h3 style="color:green">
1. Use your Google sleuthing skills to brainstorm why there were fewer than expected flights on Jan 20, May 26, and Sep 1. (Hint: they all have the same explanation.) How would these days generalise to another year?
</h3>

- January 20th was the day for Martin Luther King day
- May 26th was the day before Memorial Day weekend
- September 1st was the day before labor day
Based on the above, it seems a variable representing “holiday” or “holiday weekend” or the day before these holidays may be valuable .

<h3 style="color:green">
2. What do the three days with high positive residuals represent? How would these days generalise to another year?

```
daily %>%
top_n(3, resid)
#> # A tibble: 3 x 5
#> date n wday resid term
#> <date> <int> <ord> <dbl> <fct>
#> 1 2013-11-30 857 Sat 112. fall
#> 2 2013-12-01 987 Sun 95.5 fall
#> 3 2013-12-28 814 Sat 69.4 fall
```
</h3>

```{r}
daily <- flights %>% 
  mutate(date = make_date(year, month, day)) %>% 
  count(date)

daily <- daily %>% 
  mutate(wday = wday(date, label = TRUE))
mod <- lm(n ~ wday, data = daily)

daily <- daily %>% 
  add_residuals(mod)

daily %>% 
  top_n(3, resid)
```
  
  - These days correspond with the Saturday and Sunday of Thanksgiving, as well as the Saturday after Christmas

- These days can fall on different days of the week each year so would vary from year to year depending on which day they fell on ideally you would include some “holiday” variable to help capture the impact of these / better generalize between years

Check the absolute values

```{r}
daily %>% 
  top_n(3, abs(resid))
```
  - The days with the greatest magnitude for residuals were on Christmast Day, Thanksgiving Day, and the day after Thanksgiving
  
<h3 style="color:green">
3. Create a new variable that splits the wday variable into terms, but only for Saturdays, i.e. it should have Thurs , Fri , but Sat-summer , Sat-spring , Sat-fall . How does this model compare with the model with every combination of wday and term ? </h3>

```{r}
term <- function(date) {
  cut(date, 
    breaks = ymd(20130101, 20130605, 20130825, 20140101),
    labels = c("spring", "summer", "fall") 
  )
}

daily <- daily %>% 
  mutate(term = term(date))

# example with wday_mod
Example_term_with_sat <- daily %>% 
  mutate(wday_mod = ifelse(wday == "Sat", paste(wday, "_", term), wday)) %>%
  lm(n ~ wday_mod, data = .)

# just wday
wkday <- daily %>% 
  lm(n ~ wday, data = .)

# wday and term, no interaction...
wkday_term <- daily %>% 
  mutate(wday_mod = ifelse(wday == "Sat", paste(wday, "_", term), wday)) %>%
  lm(n ~ wday + term, data = .)

# wday and term, interaction
wkday_term_interaction <- daily %>% 
  mutate(wday_mod = ifelse(wday == "Sat", paste(wday, "_", term), wday)) %>%
  lm(n ~ wday*term, data = .)

daily %>% 
  mutate(wday_mod = ifelse(wday == "Sat", paste(wday, "_", term), wday)) %>%
  gather_predictions(Example_term_with_sat, wkday, wkday_term, wkday_term_interaction) %>% 
  ggplot(aes(date, pred, colour = wday))+
  geom_point()+
  geom_line()+
  facet_wrap(~model, ncol = 1)
```
In the example, saturday has different predicted number of flights in the summer

- when just including wkday you don’t see this differentiation

- when including wkday and term you see differentiation in the summer, though this difference is the same across all wdays, hence the increased number for Saturday’s is less than it shows-up as as compared to either the example (where the term is only interacted with for Saturday) or the wkday_term_interaction chart where the interaciton is allowed for each day of the week
- you see increases in flights across pretty much all wdays in summer, though you see the biggest difference in Saturday

Residuals of these models

```{r}
daily %>% 
  mutate(wday_mod = ifelse(wday == "Sat", paste(wday, "_", term), wday)) %>%
  gather_residuals(Example_term_with_sat, wkday, wkday_term, wkday_term_interaction) %>% 
  ggplot(aes(date, resid, colour = wday))+
  geom_point()+
  geom_line()+
  facet_wrap(~model, ncol = 1)
```  
- The graphs with saturday term and interaction across terms do not show gross changes in residuals varying by season the way the models that included just weekday or weekday and term without an interaction do.
note that you have a few days with large negative residuals43
- these likely correspond with holidays

<h3 style="color:green">
4. Create a new wday variable that combines the day of week, term (for Saturdays), and public holidays. What do the residuals of that model look like?
</h3>

First, create dataset of federal holidays. Please note we used 2013 because the dataset were from 2013.

# holiday's that could have been added: Easter, black friday
# consider adding a filter to remove Columbus day and perhaps Veteran's day
```{r}
holidays <- tribble(
  ~HolidayName, ~HolidayDate,
  "New Year's", "2013-01-01",
  "MLK", "2013-01-21",
  "President's Day", "2013-02-18", 
  "Memorial Day", "2013-05-27",
  "Independene Day", "2013-07-04",
  "Labor Day", "2013-09-02",
  "Columbus Day", "2013-10-14",
  "Veteran's Day", "2013-11-11",
  "Thanksgiving", "2013-11-28",
  "Christmas Day", "2013-12-25"
) %>% 
  mutate(HolidayDate = ymd(HolidayDate))
```

Secondly, create model with Holiday variable

```{r}
Example_term_with_sat_holiday <- daily %>% 
  mutate(wday_mod = ifelse(wday == "Sat", paste(wday, "_", term), wday)) %>%
  left_join(holidays, by = c("date" = "HolidayDate")) %>% 
  mutate(Holiday = !is.na(HolidayName)) %>% 
  lm(n ~ wday_mod + Holiday, data = .)
```

Curiously, look at residuals of model

```{r}
daily %>% 
  mutate(wday_mod = ifelse(wday == "Sat", paste(wday, "_", term), wday)) %>%
  left_join(holidays, by = c("date" = "HolidayDate")) %>% 
  mutate(Holiday = !is.na(HolidayName)) %>% 
  gather_residuals(Example_term_with_sat_holiday, Example_term_with_sat) %>% 
  ggplot(aes(date, resid, colour = wday))+
  geom_point()+
  geom_line()+
  facet_wrap(~model, ncol = 1)
```
- Notice the residuals for day’s like July 4th and Christas are closer to 0 now, though residuals for smaller holidays like MLK, President’s, Columbus, and Veteran’s Day are now positive when before they did not have such noticable abberations
- Suggests that just “holiday” is not enough to capture the relationship
* In 24.3.5.4 I show how to create a “near holiday” variable (though I do not add any new analysis after creating this)
  
<h3 style="color:green">
5. What happens if you fit a day of week effect that varies by month (i.e. n ~ wday * month )? Why is this not very helpful?
</h3>

Following previous steps, we do the following:

1. Create model

```{r}
week_month <- daily %>% 
  mutate(month = month(date) %>% as.factor()) %>% 
  lm(n ~ wday * month, data = .)
```

2. Graph predictions (with n ~ wday * term as the comparison)

```{r}
daily %>% 
  mutate(month = month(date) %>% as.factor()) %>% 
  gather_predictions(wkday_term_interaction, week_month) %>% 
  ggplot(aes(date, pred, colour = wday))+
  geom_point()+
  geom_line()+
  facet_wrap(~model, ncol = 1)
```
- This model has the most flexibility / inputs, though this makes the pattern harder to follow / interpret
- Certain decreases in the month to month model are difficult to explain, for example the decrease in the month of May

Graph residuals (with n ~ wday * term as the comparison)
```{r}
daily %>% 
  mutate(month = month(date) %>% as.factor()) %>% 
  gather_residuals(wkday_term_interaction, week_month) %>% 
  ggplot(aes(date, resid, colour = wday))+
  geom_point()+
  geom_line()+
  facet_wrap(~model, ncol = 1)
```
The residuals seem to partially explain some of these inexplicable ups / downs:

- For the model that incorporates an interaciton with month, you see the residuals in months with a holiday tend to cause the associated day of the week the holiday fell on to then have high residuals on the non-holiday days, an effect thta is less pronounced on the models interacted with term
-  The reason for this is that for the monthly variables there are only 4-5 week days in each month, so a holiday on one of these can substantially impact the expected number of flights on the weekend in that month (i.e. the prediction is based just on 4-5 observations). For the term interaction you have more like 12 observations to get an expected value, so while there is still an aberration on that day, the other days predictions are less affected


<h3 style="color:green">
6. What would you expect the model n ~ wday + ns(date, 5) to look like? Knowing what you know about the data, why would you expect it to be not particularly effective?
</h3>


I would expect to see a similar overall pattern, but with more smoothed affects. Let’s check what these actually look like below.

```{r}
wkday_term_ns <- daily %>% 
  mutate(wday_mod = ifelse(wday == "Sat", paste(wday, "_", term), wday)) %>% 
  lm(n ~ wday + splines::ns(date, 5), data = .)

wkday_term_interaction_ns <- lm(n ~ wday * splines::ns(date, 5), data = daily)
```

Look at predictions (light gray are actuals)

```{r}
daily %>% 
  mutate(wday_mod = ifelse(wday == "Sat", paste(wday, "_", term), wday)) %>% 
  gather_predictions(wkday_term_ns, wkday_term_interaction_ns) %>% 
  ggplot(aes(date, pred, colour = wday))+
  geom_point()+
  geom_line(aes(x = date, y = n, group = wday), colour = "gray", alpha = 0.5)+
  geom_line()+
  facet_wrap(~model, ncol = 1)
```
Look at residuals (in light gray are actuals)

```{r}
daily %>% 
  mutate(wday_mod = ifelse(wday == "Sat", paste(wday, "_", term), wday)) %>% 
  gather_residuals(wkday_term_ns, wkday_term_interaction_ns) %>% 
  ggplot(aes(date, resid, colour = wday))+
  geom_point()+
  geom_line(aes(x = date, y = n, group = wday), colour = "gray", alpha = 0.5)+
  geom_line()+
  facet_wrap(~model, ncol = 1)
```
  
<h3 style="color:green">
7. We hypothesised that people leaving on Sundays are more likely to be business travellers who need to be somewhere on Monday. Explore that hypothesis by seeing how it breaks down based on distance and time: if it’s true, you’d expect to see more Sunday evening flights to places that are far away.

</h3>

-Comparing the average distances of flights by day of week, Sunday flights are the second longest. Saturday flights are the longest on average. Saturday may have the longest flights on average because there are fewer regularly scheduled short business/commuter flights on the weekends but that is speculation.

```{r}
flights %>% 
  mutate(date = lubridate::make_date(year, month, day),
         wday = wday(date, label = TRUE)) %>% 
  select(date, wday, distance) %>%
  filter(distance < 3000) %>% 
  ggplot(aes(wday, distance))+
  geom_boxplot()
```
- 25th and 75th percentiles aren’t visibly different, but median is a little higher
- The same is the case for Saturday travel which does not seem to fit into this hypothesis as neatly. The effect seems more general to the weekend than just Saturday, and there seem like there may be other potential explanations than “business travel”

Try pointrange with mean and standard error of the mean (sd / sqrt(n)).

```{r}
flights %>%
  mutate(
    date = make_date(year, month, day),
    wday = wday(date, label = TRUE)
  ) %>%
  ggplot(aes(y = distance, x = wday)) +
  stat_summary() +
  labs(x = "Day of Week", y = "Average Distance")
```

<h3 style="color:green">
8. It’s a little frustrating that Sunday and Saturday are on separate ends of the plot. Write a small function to set the levels of the factor so that the week starts on Monday.
</h3>

-For the function fct_relevel(). Use fct_relevel() to put all levels in-front of the first level (“Sunday”).

```{r}
monday_first <- function(x) {
  fct_relevel(x, levels(x)[-1])
}
```
Now Monday is the first day of the week.

```{r}
daily <- daily %>%
  mutate(wday = wday(date, label = TRUE))
ggplot(daily, aes(monday_first(wday), n)) +
  geom_boxplot() +
  labs(x = "Day of Week", y = "Number of flights")
```

<h2 style="color:magenta">25.2.5 Exercises</h2>

Let's prepare the datasets:

```{r}
by_country <- gapminder::gapminder %>% 
  group_by(country, continent) %>% 
  nest()
country_model <- function(df) {
  lm(lifeExp ~ year, data = df)
}
```

```{r}
by_country2 <- by_country %>% 
  mutate(model = purrr::map(data, country_model))

by_country2 %>% 
  arrange(continent, country)

```


- IMPORTANT: <B>unnesting</B>, another dataframe with the residuals included and then unnest

```{R}
by_country3 <- by_country2 %>%
  mutate(resids = purrr::map2(data, model, add_residuals))
resids <- by_country3 %>% 
  unnest(resids)

resids
```

<h3 style="color:green">
1. A linear trend seems to be slightly too simple for the overall trend. Can you do better with
a quadratic polynomial? How can you interpret the coefficients of the quadratic? (Hint
you might want to transform year so that it has mean zero.)
</h3>

Creating  functions

```{r}
# funciton to center value
center_value <- function(df){
  df %>% 
    mutate(year_cent = year - mean(year))
}

# this function allows me to input any text to "var" to customize the inputs
# to the model, default are a linear and quadratic term for year (centered)
lm_quad_2 <- function(df, var = "year_cent + I(year_cent^2)"){
  lm(as.formula(paste("lifeExp ~ ", var)), data = df)
}
```

Creating dataframe with evaluation metrics

```{r}
by_country3_quad <- by_country3 %>% 
  mutate(
    # create centered data
    data_cent = purrr::map(data, center_value), 
    # create quadratic models
    mod_quad = purrr::map(data_cent, lm_quad_2), 
    # get model evaluation stats from original model
    glance_mod = purrr::map(model, broom::glance), 
    # get model evaluation stats from quadratic model
    glance_quad = purrr::map(mod_quad, broom::glance)) 
```

Creating plots

```{r}
by_country3_quad %>% 
  unnest(glance_mod, glance_quad, names_sep = "_") %>% 
  
  gather(glance_mod_r.squared, glance_quad_r.squared, 
         key = "order", value = "r.squared") %>% 
  ggplot(aes(x = continent, y = r.squared, colour = continent)) +
  geom_boxplot() +
  facet_wrap(~order)
```  
-The quadratic trend seems to do better –> indicated by the distribution of the R^2 values being closer to one. The level of improvement seems especially pronounced for African countries.
Let’s check this closer by looking at percentage point improvement in R^2 in chart below

```{r}
by_country3_quad %>% 
  mutate(quad_coefs = map(mod_quad, broom::tidy)) %>% 
  unnest(glance_mod, .sep = "_") %>% 
  unnest(glance_quad) %>% 
  mutate(bad_fit = glance_mod_r.squared < 0.25,
         R.squ_ppt_increase = r.squared - glance_mod_r.squared) %>% 
  ggplot(aes(x = continent, y = R.squ_ppt_increase))+
  # geom_quasirandom(aes(alpha = bad_fit), colour = "black")+
  geom_boxplot(alpha = 0.1, colour = "dark grey")+
  geom_quasirandom(aes(colour = continent))+
  labs(title = "Percentage point (PPT) improvement in R squared value", 
       subtitle = "(When adding a quadratic term to the linear regression model)")
```
- View predictions from linear model with quadratic term (of countries where linear trend did not capture relationship)

```{r}
bad_fit <- by_country3 %>% 
  mutate(glance = purrr::map(model, broom::glance)) %>% 
  unnest(glance, .drop = TRUE) %>% 
  filter(r.squared < 0.25)

#solve with join with bad_fit
by_country3_quad %>% 
  semi_join(bad_fit, by = "country") %>% 
  mutate(data_preds = purrr::map2(data_cent, mod_quad, add_predictions)) %>% 
  unnest(data_preds) %>% 
  ggplot(aes(x = year, group = country))+
  geom_point(aes(y = lifeExp, colour = country))+
  geom_line(aes(y = pred, colour = country))+
  facet_wrap(~country)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

- while the quadratic model does a better job fitting the model than a linear term does, I wouldn’t say it does a good job of fitting the model
- It looks like the trends are generally consistent rates of improvement and then there is a sudden drop-off associated with some event, hence an intervention variable may be a more appropriate method for modeling this pattern


<h3 style="color:green">
2. Explore other methods for visualising the distribution of per continent. You might want to try the ggbeeswarm package, which provides similar methods for avoiding overlaps as jitter, but uses deterministic methods.
</h3>


-visualizing of linear model

```{r}
by_country3_quad %>% 
  unnest(glance_mod) %>% 
  ggplot(aes(x = continent, y = r.squared, colour = continent))+
  geom_boxplot(alpha = 0.1, colour = "dark grey")+
  ggbeeswarm::geom_quasirandom()
```
- I like geom_quasirandom() the best as an overlay on boxplot, it keeps things centered and doesn’t have the gravitational pull affect that makes geom_beeswarm() become a little misaligned, it also works well here over geom_jitter() as the points stay better around their true value

<h3 style="color:green">
3. To create the last plot (showing the data for the countries with the worst model fits), we needed two steps: we created a data frame with one row per country and then semi- joined it to the original dataset. It’s possible to avoid this join if we use unnest() instead of unnest(.drop = TRUE) . How?
</h3>

- First, filter by r.squared and then unnest
```{r}
by_country3_quad %>% 
  mutate(data_preds = purrr::map2(data_cent, mod_quad, add_predictions)) %>% 
  unnest(glance_mod) %>% 
  mutate(bad_fit = r.squared < 0.25) %>% 
  filter(bad_fit) %>% 
  unnest(data_preds) %>% 
  ggplot(aes(x = year, group = country))+
  geom_point(aes(y = lifeExp, colour = country))+
  geom_line(aes(y = pred, colour = country))+
  facet_wrap(~country)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
Or, join all graphs together

```{r}
gapminder %>%
  group_by(country, continent) %>%
  nest() %>%
  mutate(model = map(data, ~lm(lifeExp ~ year, .))) %>%
  mutate(glance = map(model, broom::glance)) %>%
  unnest(glance) %>%
  unnest(data) %>%
  filter(r.squared < 0.25) %>%
  ggplot(aes(year, lifeExp)) +
  geom_line(aes(color = country))
```


<h1 style="color:blue"> CONCLUSIONS </h1>

<p>
While doing the activities, I have learned the following three main categories:
</p>

- how models work mechanistically, focusing on the important family of linear models. You’ll learn general tools for gaining insight into what a predictive model tells you about your data, focusing on simple simulated datasets.


- how to use models to pull out known patterns in real data. Once you have recognized an important pattern it’s useful to make it explicit in a model, because then you can more easily see the subtler signals that remain.

- how to use many simple models to help understand complex datasets. This is a powerful technique, but to access it you’ll need to combine modeling and programming tools.


<b><u> Basic modeling concepts: </u> </b>
<div>
  In the basic concept of models, I learned that the majority of modeling functions in R use a standard conversion from formulas to functions. I also encountered and seen its demonstration in visualizing models especially predictions and residuals. In R programming, predictive models are extremely useful for forecasting future outcomes and estimating metrics that are impractical to measure.Sometimes, It’s also useful to see what the model doesn’t capture, the so-called residuals that are left after subtracting the predictions from the data. Residuals are powerful because they allow us to use models to remove striking patterns so we can study the subtler trends that remain. In summary, I understand now how linear models worked, and learned some basic tools for understanding what a model is telling you about your data. 
</div>

<b><u> Building models take-aways: </u> </b>
<p>
In building models, we did use real and complex data which we were able to show how we can progressively build up
a model to aid your understanding of the data. THis is particularly important because we need to find pattern in transitioning from implicit knowledge in the given data to explicit knowledge in a <u>quantitative model</u>. Having built a predictive analytic and quantitative model,  we were able to understand how well the model performs. We will now apply the model to the observations in the complex dataset to evaluate its performance. This is the purpose of the validation dataset. We evaluate a model by making predictions on observations tha were not used in building the model. These observations will need to have a known outcome so that we can compare the model prediction against the known outcome. Generally the evaluation of a model over the training dataset will result in a biased estimate of
the actual model performance—after all, that is the data that was used to build the model and so the model builder should do well on that dataset. We were introduced the concept of making predictions over new, unseen, or hold-out observations using the model we have built. We used these predictions over the validation dataset to provide
an unbiased estimate of the quality of the predictions made by the model. This may lead us to fine-tune some of the parameters we have available for building a decision tree.
</p>

<b><u> Many models with ```purrr``` and ```broom```: </u> </b>
<p>
We were able to dive into nested data and list-columns. The data frames are in a list, so we were able to use ```purrr::map()```. Here in this part, we dissected the general measurements of model quality when we used a different approach using the ```broom``` package. These ideas are a stretch for me as it somewhat high-level already just like using ```broom::glance()``` to extract some model quality metrics as well as ```nest()``` and ```unnest````.

</p>
